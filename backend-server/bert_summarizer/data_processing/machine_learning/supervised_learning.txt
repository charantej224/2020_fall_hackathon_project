supervised learning is requires training labeled datas. for example, in order to the classification  a supervised learning task ,
you’ll need to the first label the data you’ll use to the train the model to classify data into your labeled groups.
unsupervised learning, in contrast, does not a require labeling data explicitly.
supervised learning   this model learns from the labeled data and makes a future prediction as output
unsupervised learning   this model uses unlabeled input data and allows the algorithm to act on that information without guidance.
in supervised machine learning algorithms, we have to provide labelled data, for example, prediction of stock market prices,
whereas in unsupervised we need not have labelled data, for example, classification of emails into spam and non spam.
overfitting is a situation that occurs when a model learns the training set too well, taking up random fluctuations in the training data as concepts.
these impact the model’s ability to generalize and don’t apply to new data. when a model is given the training data, it shows 100 percent
accuracy—technically a slight loss. but, when we use the test data, there may be an error and low efficiency. this condition is known as overfitting.
there are multiple ways of avoiding overfitting, such as regularization, cross validation methods like k folds and making a simple model with lesser variables, parameters, the variance can be reduced.
applications of supervised machine learning include email spam detection, healthcare diagnosis, sentiment analysis and fraud detection.
supervised learning is where you have input variables  x  and an output variable  y  and you use an algorithm to learn the mapping function
from the input to the output. the goal is to approximate the mapping function so well that when you have new input data  x  that you can predict the
output variables  y  for that data. it is called supervised learning because the process of an algorithm learning from the training dataset
can be thought of as a teacher supervising the learning process.
supervised  all data is labeled and the algorithms learn to predict the output from the input data.
unsupervised  all data is unlabeled and the algorithms learn to inherent structure from the input data.
semi supervised  some data is labeled but most of it is unlabeled and a mixture of supervised and unsupervised techniques can be used.
linear regression, nearest neighbor, guassian naive bayes, decision trees, support vector machine  svm , random forest.

